# üöÄ Next Phase Technical Implementation Plan
## reVoAgent: Enhanced Integration & Production Optimization

**Date**: 2025-06-12  
**Phase**: Post-Architecture Integration Enhancement  
**Focus**: Real-time Communication, Agent Coordination, Production Monitoring

---

## üìä **Current State Analysis**

### ‚úÖ **Strengths Identified**
- **Three-Engine Architecture**: Fully implemented and operational
- **Backend Infrastructure**: Robust FastAPI with WebSocket support
- **Frontend Foundation**: Modern React TypeScript with glassmorphism
- **Memory Integration**: Cognee system integrated
- **Agent Ecosystem**: 20+ specialized agents implemented
- **Production Ready**: Docker, K8s, monitoring infrastructure

### ‚ö†Ô∏è **Integration Gaps to Address**
1. **Frontend-Backend Real-time Communication**: WebSocket integration needs enhancement
2. **Agent Coordination**: Status monitoring and coordination between agents
3. **Production Monitoring**: Observability and monitoring optimization
4. **Three-Engine Coordination**: Enhanced coordination between engines

---

## üéØ **Priority 1: Enhanced Real-time Communication**

### **Current State**
- Basic WebSocket implementation exists
- Frontend has WebSocket hooks but limited integration
- Agent status updates not real-time

### **Implementation Plan**

#### **1.1 Enhanced WebSocket Service**
```typescript
// Enhanced WebSocket service with reconnection and state management
class EnhancedWebSocketService {
  private ws: WebSocket | null = null;
  private reconnectAttempts = 0;
  private maxReconnectAttempts = 5;
  private reconnectInterval = 1000;
  private messageQueue: any[] = [];
  private subscribers = new Map<string, Set<Function>>();

  connect(url: string): Promise<void> {
    return new Promise((resolve, reject) => {
      try {
        this.ws = new WebSocket(url);
        
        this.ws.onopen = () => {
          console.log('WebSocket connected');
          this.reconnectAttempts = 0;
          this.flushMessageQueue();
          resolve();
        };

        this.ws.onmessage = (event) => {
          const data = JSON.parse(event.data);
          this.handleMessage(data);
        };

        this.ws.onclose = () => {
          console.log('WebSocket disconnected');
          this.handleReconnect();
        };

        this.ws.onerror = (error) => {
          console.error('WebSocket error:', error);
          reject(error);
        };
      } catch (error) {
        reject(error);
      }
    });
  }

  private handleReconnect() {
    if (this.reconnectAttempts < this.maxReconnectAttempts) {
      this.reconnectAttempts++;
      setTimeout(() => {
        this.connect(this.getWebSocketUrl());
      }, this.reconnectInterval * this.reconnectAttempts);
    }
  }

  subscribe(channel: string, callback: Function) {
    if (!this.subscribers.has(channel)) {
      this.subscribers.set(channel, new Set());
    }
    this.subscribers.get(channel)!.add(callback);
  }

  unsubscribe(channel: string, callback: Function) {
    this.subscribers.get(channel)?.delete(callback);
  }

  send(message: any) {
    if (this.ws?.readyState === WebSocket.OPEN) {
      this.ws.send(JSON.stringify(message));
    } else {
      this.messageQueue.push(message);
    }
  }

  private handleMessage(data: any) {
    const { channel, payload } = data;
    const channelSubscribers = this.subscribers.get(channel);
    if (channelSubscribers) {
      channelSubscribers.forEach(callback => callback(payload));
    }
  }

  private flushMessageQueue() {
    while (this.messageQueue.length > 0) {
      const message = this.messageQueue.shift();
      this.send(message);
    }
  }
}
```

#### **1.2 Real-time Agent Status Component**
```typescript
// Real-time agent status monitoring component
import React, { useState, useEffect } from 'react';
import { useWebSocket } from '../hooks/useWebSocket';

interface AgentStatus {
  id: string;
  name: string;
  status: 'idle' | 'processing' | 'error' | 'offline';
  currentTask?: string;
  performance: {
    tasksCompleted: number;
    averageResponseTime: number;
    successRate: number;
  };
  lastUpdate: string;
}

export const RealTimeAgentMonitor: React.FC = () => {
  const [agents, setAgents] = useState<AgentStatus[]>([]);
  const { subscribe, send } = useWebSocket();

  useEffect(() => {
    // Subscribe to agent status updates
    subscribe('agent_status', (data: AgentStatus) => {
      setAgents(prev => {
        const index = prev.findIndex(agent => agent.id === data.id);
        if (index >= 0) {
          const updated = [...prev];
          updated[index] = data;
          return updated;
        }
        return [...prev, data];
      });
    });

    // Request initial agent status
    send({
      type: 'get_agent_status',
      payload: { all: true }
    });
  }, [subscribe, send]);

  return (
    <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
      {agents.map(agent => (
        <div key={agent.id} className="bg-white/10 backdrop-blur-md rounded-lg p-4">
          <div className="flex items-center justify-between mb-2">
            <h3 className="font-semibold text-white">{agent.name}</h3>
            <StatusIndicator status={agent.status} />
          </div>
          
          {agent.currentTask && (
            <div className="text-sm text-gray-300 mb-2">
              Current: {agent.currentTask}
            </div>
          )}
          
          <div className="grid grid-cols-3 gap-2 text-xs">
            <div className="text-center">
              <div className="text-blue-400">{agent.performance.tasksCompleted}</div>
              <div className="text-gray-400">Tasks</div>
            </div>
            <div className="text-center">
              <div className="text-green-400">{agent.performance.averageResponseTime}ms</div>
              <div className="text-gray-400">Avg Time</div>
            </div>
            <div className="text-center">
              <div className="text-purple-400">{agent.performance.successRate}%</div>
              <div className="text-gray-400">Success</div>
            </div>
          </div>
        </div>
      ))}
    </div>
  );
};
```

---

## üéØ **Priority 2: Enhanced Agent Coordination**

### **Implementation Plan**

#### **2.1 Agent Coordination Service**
```python
# Enhanced agent coordination service
from typing import Dict, List, Any, Optional
import asyncio
import json
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum

class AgentStatus(Enum):
    IDLE = "idle"
    PROCESSING = "processing"
    ERROR = "error"
    OFFLINE = "offline"

@dataclass
class AgentMetrics:
    tasks_completed: int = 0
    average_response_time: float = 0.0
    success_rate: float = 100.0
    last_activity: Optional[datetime] = None
    error_count: int = 0

@dataclass
class AgentState:
    id: str
    name: str
    status: AgentStatus
    current_task: Optional[str] = None
    metrics: AgentMetrics = None
    capabilities: List[str] = None
    load_percentage: float = 0.0

class EnhancedAgentCoordinator:
    def __init__(self, websocket_manager):
        self.agents: Dict[str, AgentState] = {}
        self.task_queue: asyncio.Queue = asyncio.Queue()
        self.websocket_manager = websocket_manager
        self.coordination_rules = {}
        self.performance_thresholds = {
            'max_response_time': 5000,  # ms
            'min_success_rate': 85,     # %
            'max_error_rate': 10        # %
        }

    async def register_agent(self, agent_id: str, agent_name: str, capabilities: List[str]):
        """Register a new agent with the coordinator"""
        self.agents[agent_id] = AgentState(
            id=agent_id,
            name=agent_name,
            status=AgentStatus.IDLE,
            metrics=AgentMetrics(),
            capabilities=capabilities
        )
        
        await self.broadcast_agent_update(agent_id)
        
    async def update_agent_status(self, agent_id: str, status: AgentStatus, 
                                current_task: Optional[str] = None):
        """Update agent status and broadcast to clients"""
        if agent_id in self.agents:
            self.agents[agent_id].status = status
            self.agents[agent_id].current_task = current_task
            self.agents[agent_id].metrics.last_activity = datetime.now()
            
            await self.broadcast_agent_update(agent_id)
            
    async def update_agent_metrics(self, agent_id: str, 
                                 response_time: float, success: bool):
        """Update agent performance metrics"""
        if agent_id not in self.agents:
            return
            
        agent = self.agents[agent_id]
        metrics = agent.metrics
        
        # Update metrics
        metrics.tasks_completed += 1
        if success:
            # Update average response time
            if metrics.average_response_time == 0:
                metrics.average_response_time = response_time
            else:
                metrics.average_response_time = (
                    (metrics.average_response_time * (metrics.tasks_completed - 1) + response_time) 
                    / metrics.tasks_completed
                )
        else:
            metrics.error_count += 1
            
        # Calculate success rate
        metrics.success_rate = (
            (metrics.tasks_completed - metrics.error_count) / metrics.tasks_completed * 100
        )
        
        # Check performance thresholds
        await self.check_performance_thresholds(agent_id)
        
        await self.broadcast_agent_update(agent_id)

    async def check_performance_thresholds(self, agent_id: str):
        """Check if agent performance meets thresholds"""
        agent = self.agents[agent_id]
        metrics = agent.metrics
        
        alerts = []
        
        if metrics.average_response_time > self.performance_thresholds['max_response_time']:
            alerts.append(f"High response time: {metrics.average_response_time}ms")
            
        if metrics.success_rate < self.performance_thresholds['min_success_rate']:
            alerts.append(f"Low success rate: {metrics.success_rate}%")
            
        error_rate = (metrics.error_count / metrics.tasks_completed * 100) if metrics.tasks_completed > 0 else 0
        if error_rate > self.performance_thresholds['max_error_rate']:
            alerts.append(f"High error rate: {error_rate}%")
            
        if alerts:
            await self.send_performance_alert(agent_id, alerts)

    async def find_best_agent(self, required_capabilities: List[str]) -> Optional[str]:
        """Find the best available agent for a task"""
        available_agents = [
            agent for agent in self.agents.values()
            if agent.status == AgentStatus.IDLE and
            all(cap in agent.capabilities for cap in required_capabilities)
        ]
        
        if not available_agents:
            return None
            
        # Sort by performance metrics
        best_agent = min(available_agents, key=lambda a: (
            a.metrics.average_response_time,
            -a.metrics.success_rate,
            a.load_percentage
        ))
        
        return best_agent.id

    async def broadcast_agent_update(self, agent_id: str):
        """Broadcast agent status update to all connected clients"""
        if agent_id in self.agents:
            agent_data = asdict(self.agents[agent_id])
            # Convert datetime to string for JSON serialization
            if agent_data['metrics']['last_activity']:
                agent_data['metrics']['last_activity'] = agent_data['metrics']['last_activity'].isoformat()
                
            await self.websocket_manager.broadcast(json.dumps({
                'channel': 'agent_status',
                'payload': agent_data
            }))

    async def send_performance_alert(self, agent_id: str, alerts: List[str]):
        """Send performance alert to monitoring systems"""
        alert_data = {
            'agent_id': agent_id,
            'agent_name': self.agents[agent_id].name,
            'alerts': alerts,
            'timestamp': datetime.now().isoformat()
        }
        
        await self.websocket_manager.broadcast(json.dumps({
            'channel': 'performance_alert',
            'payload': alert_data
        }))

    async def get_system_overview(self) -> Dict[str, Any]:
        """Get overall system status and metrics"""
        total_agents = len(self.agents)
        active_agents = len([a for a in self.agents.values() if a.status != AgentStatus.OFFLINE])
        processing_agents = len([a for a in self.agents.values() if a.status == AgentStatus.PROCESSING])
        
        avg_response_time = sum(a.metrics.average_response_time for a in self.agents.values()) / total_agents if total_agents > 0 else 0
        avg_success_rate = sum(a.metrics.success_rate for a in self.agents.values()) / total_agents if total_agents > 0 else 0
        
        return {
            'total_agents': total_agents,
            'active_agents': active_agents,
            'processing_agents': processing_agents,
            'system_metrics': {
                'average_response_time': avg_response_time,
                'average_success_rate': avg_success_rate,
                'total_tasks_completed': sum(a.metrics.tasks_completed for a in self.agents.values())
            }
        }
```

#### **2.2 Enhanced Backend WebSocket Handler**
```python
# Enhanced WebSocket handler for real-time communication
from fastapi import WebSocket, WebSocketDisconnect
import json
import asyncio
from typing import Dict, Set

class EnhancedWebSocketManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.subscriptions: Dict[str, Set[str]] = {}  # channel -> set of connection_ids
        
    async def connect(self, websocket: WebSocket, connection_id: str):
        await websocket.accept()
        self.active_connections[connection_id] = websocket
        print(f"WebSocket connected: {connection_id}")
        
    def disconnect(self, connection_id: str):
        if connection_id in self.active_connections:
            del self.active_connections[connection_id]
            
        # Remove from all subscriptions
        for channel_subs in self.subscriptions.values():
            channel_subs.discard(connection_id)
            
        print(f"WebSocket disconnected: {connection_id}")
        
    async def send_personal_message(self, message: str, connection_id: str):
        if connection_id in self.active_connections:
            try:
                await self.active_connections[connection_id].send_text(message)
            except:
                self.disconnect(connection_id)
                
    async def broadcast(self, message: str):
        disconnected = []
        for connection_id, websocket in self.active_connections.items():
            try:
                await websocket.send_text(message)
            except:
                disconnected.append(connection_id)
                
        for connection_id in disconnected:
            self.disconnect(connection_id)
            
    async def broadcast_to_channel(self, channel: str, message: str):
        if channel not in self.subscriptions:
            return
            
        disconnected = []
        for connection_id in self.subscriptions[channel]:
            if connection_id in self.active_connections:
                try:
                    await self.active_connections[connection_id].send_text(message)
                except:
                    disconnected.append(connection_id)
                    
        for connection_id in disconnected:
            self.disconnect(connection_id)
            
    def subscribe(self, connection_id: str, channel: str):
        if channel not in self.subscriptions:
            self.subscriptions[channel] = set()
        self.subscriptions[channel].add(connection_id)
        
    def unsubscribe(self, connection_id: str, channel: str):
        if channel in self.subscriptions:
            self.subscriptions[channel].discard(connection_id)

# WebSocket endpoint with enhanced message handling
@app.websocket("/ws/{connection_id}")
async def websocket_endpoint(websocket: WebSocket, connection_id: str):
    await enhanced_websocket_manager.connect(websocket, connection_id)
    
    try:
        while True:
            data = await websocket.receive_text()
            message = json.loads(data)
            
            message_type = message.get('type')
            payload = message.get('payload', {})
            
            if message_type == 'subscribe':
                channel = payload.get('channel')
                if channel:
                    enhanced_websocket_manager.subscribe(connection_id, channel)
                    
            elif message_type == 'unsubscribe':
                channel = payload.get('channel')
                if channel:
                    enhanced_websocket_manager.unsubscribe(connection_id, channel)
                    
            elif message_type == 'get_agent_status':
                if payload.get('all'):
                    overview = await agent_coordinator.get_system_overview()
                    await enhanced_websocket_manager.send_personal_message(
                        json.dumps({
                            'channel': 'system_overview',
                            'payload': overview
                        }),
                        connection_id
                    )
                    
            elif message_type == 'agent_task':
                # Handle agent task requests
                agent_id = payload.get('agent_id')
                task_description = payload.get('task')
                
                if agent_id and task_description:
                    await agent_coordinator.update_agent_status(
                        agent_id, AgentStatus.PROCESSING, task_description
                    )
                    
    except WebSocketDisconnect:
        enhanced_websocket_manager.disconnect(connection_id)
```

---

## üéØ **Priority 3: Production Monitoring Enhancement**

### **Implementation Plan**

#### **3.1 Enhanced Monitoring Dashboard**
```typescript
// Production monitoring dashboard component
import React, { useState, useEffect } from 'react';
import { Line, Bar, Doughnut } from 'react-chartjs-2';

interface SystemMetrics {
  cpu_usage: number;
  memory_usage: number;
  disk_usage: number;
  network_io: {
    bytes_sent: number;
    bytes_received: number;
  };
  response_times: number[];
  error_rates: number[];
  throughput: number;
}

export const ProductionMonitoringDashboard: React.FC = () => {
  const [metrics, setMetrics] = useState<SystemMetrics | null>(null);
  const [alerts, setAlerts] = useState<any[]>([]);
  const { subscribe } = useWebSocket();

  useEffect(() => {
    subscribe('system_metrics', (data: SystemMetrics) => {
      setMetrics(data);
    });

    subscribe('system_alerts', (alert: any) => {
      setAlerts(prev => [alert, ...prev.slice(0, 9)]); // Keep last 10 alerts
    });

    // Request initial metrics
    fetch('/api/monitoring/metrics')
      .then(res => res.json())
      .then(setMetrics);
  }, [subscribe]);

  if (!metrics) {
    return <div className="flex items-center justify-center h-64">Loading metrics...</div>;
  }

  return (
    <div className="space-y-6">
      {/* System Health Overview */}
      <div className="grid grid-cols-1 md:grid-cols-4 gap-4">
        <MetricCard
          title="CPU Usage"
          value={`${metrics.cpu_usage}%`}
          status={metrics.cpu_usage > 80 ? 'critical' : metrics.cpu_usage > 60 ? 'warning' : 'good'}
        />
        <MetricCard
          title="Memory Usage"
          value={`${metrics.memory_usage}%`}
          status={metrics.memory_usage > 85 ? 'critical' : metrics.memory_usage > 70 ? 'warning' : 'good'}
        />
        <MetricCard
          title="Disk Usage"
          value={`${metrics.disk_usage}%`}
          status={metrics.disk_usage > 90 ? 'critical' : metrics.disk_usage > 75 ? 'warning' : 'good'}
        />
        <MetricCard
          title="Throughput"
          value={`${metrics.throughput} req/min`}
          status="good"
        />
      </div>

      {/* Performance Charts */}
      <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
        <div className="bg-white/10 backdrop-blur-md rounded-lg p-6">
          <h3 className="text-lg font-semibold text-white mb-4">Response Times</h3>
          <Line
            data={{
              labels: Array.from({ length: metrics.response_times.length }, (_, i) => i),
              datasets: [{
                label: 'Response Time (ms)',
                data: metrics.response_times,
                borderColor: 'rgb(59, 130, 246)',
                backgroundColor: 'rgba(59, 130, 246, 0.1)',
                tension: 0.4
              }]
            }}
            options={{
              responsive: true,
              scales: {
                y: {
                  beginAtZero: true,
                  grid: { color: 'rgba(255, 255, 255, 0.1)' },
                  ticks: { color: 'white' }
                },
                x: {
                  grid: { color: 'rgba(255, 255, 255, 0.1)' },
                  ticks: { color: 'white' }
                }
              },
              plugins: {
                legend: { labels: { color: 'white' } }
              }
            }}
          />
        </div>

        <div className="bg-white/10 backdrop-blur-md rounded-lg p-6">
          <h3 className="text-lg font-semibold text-white mb-4">Error Rates</h3>
          <Bar
            data={{
              labels: ['Last Hour', 'Last 6h', 'Last 24h', 'Last Week'],
              datasets: [{
                label: 'Error Rate (%)',
                data: metrics.error_rates,
                backgroundColor: [
                  'rgba(239, 68, 68, 0.8)',
                  'rgba(245, 101, 101, 0.8)',
                  'rgba(248, 113, 113, 0.8)',
                  'rgba(252, 165, 165, 0.8)'
                ]
              }]
            }}
            options={{
              responsive: true,
              scales: {
                y: {
                  beginAtZero: true,
                  max: 10,
                  grid: { color: 'rgba(255, 255, 255, 0.1)' },
                  ticks: { color: 'white' }
                },
                x: {
                  grid: { color: 'rgba(255, 255, 255, 0.1)' },
                  ticks: { color: 'white' }
                }
              },
              plugins: {
                legend: { labels: { color: 'white' } }
              }
            }}
          />
        </div>
      </div>

      {/* Recent Alerts */}
      <div className="bg-white/10 backdrop-blur-md rounded-lg p-6">
        <h3 className="text-lg font-semibold text-white mb-4">Recent Alerts</h3>
        <div className="space-y-2">
          {alerts.length === 0 ? (
            <div className="text-gray-400">No recent alerts</div>
          ) : (
            alerts.map((alert, index) => (
              <div key={index} className={`p-3 rounded-lg ${
                alert.severity === 'critical' ? 'bg-red-500/20 border border-red-500/50' :
                alert.severity === 'warning' ? 'bg-yellow-500/20 border border-yellow-500/50' :
                'bg-blue-500/20 border border-blue-500/50'
              }`}>
                <div className="flex items-center justify-between">
                  <span className="text-white font-medium">{alert.title}</span>
                  <span className="text-sm text-gray-300">{alert.timestamp}</span>
                </div>
                <div className="text-sm text-gray-300 mt-1">{alert.description}</div>
              </div>
            ))
          )}
        </div>
      </div>
    </div>
  );
};

const MetricCard: React.FC<{
  title: string;
  value: string;
  status: 'good' | 'warning' | 'critical';
}> = ({ title, value, status }) => {
  const statusColors = {
    good: 'border-green-500/50 bg-green-500/10',
    warning: 'border-yellow-500/50 bg-yellow-500/10',
    critical: 'border-red-500/50 bg-red-500/10'
  };

  return (
    <div className={`bg-white/10 backdrop-blur-md rounded-lg p-4 border ${statusColors[status]}`}>
      <div className="text-sm text-gray-300">{title}</div>
      <div className="text-2xl font-bold text-white mt-1">{value}</div>
    </div>
  );
};
```

#### **3.2 Enhanced Monitoring Backend Service**
```python
# Enhanced monitoring service
import psutil
import asyncio
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any
import aioredis
from collections import deque

class EnhancedMonitoringService:
    def __init__(self, websocket_manager, redis_url: str = "redis://localhost:6379"):
        self.websocket_manager = websocket_manager
        self.redis_url = redis_url
        self.redis = None
        self.metrics_history = {
            'response_times': deque(maxlen=100),
            'error_rates': deque(maxlen=24),  # 24 hours
            'cpu_usage': deque(maxlen=60),    # 60 minutes
            'memory_usage': deque(maxlen=60),
            'throughput': deque(maxlen=60)
        }
        self.alert_thresholds = {
            'cpu_usage': 80,
            'memory_usage': 85,
            'disk_usage': 90,
            'response_time': 5000,  # ms
            'error_rate': 5  # %
        }
        self.running = False

    async def initialize(self):
        """Initialize monitoring service"""
        try:
            self.redis = await aioredis.from_url(self.redis_url)
        except Exception as e:
            print(f"Redis connection failed: {e}")
            self.redis = None

    async def start_monitoring(self):
        """Start continuous monitoring"""
        self.running = True
        
        # Start monitoring tasks
        asyncio.create_task(self.collect_system_metrics())
        asyncio.create_task(self.collect_application_metrics())
        asyncio.create_task(self.check_alerts())
        
    async def stop_monitoring(self):
        """Stop monitoring"""
        self.running = False
        if self.redis:
            await self.redis.close()

    async def collect_system_metrics(self):
        """Collect system-level metrics"""
        while self.running:
            try:
                # CPU usage
                cpu_percent = psutil.cpu_percent(interval=1)
                self.metrics_history['cpu_usage'].append(cpu_percent)
                
                # Memory usage
                memory = psutil.virtual_memory()
                memory_percent = memory.percent
                self.metrics_history['memory_usage'].append(memory_percent)
                
                # Disk usage
                disk = psutil.disk_usage('/')
                disk_percent = (disk.used / disk.total) * 100
                
                # Network I/O
                network = psutil.net_io_counters()
                
                metrics = {
                    'cpu_usage': cpu_percent,
                    'memory_usage': memory_percent,
                    'disk_usage': disk_percent,
                    'network_io': {
                        'bytes_sent': network.bytes_sent,
                        'bytes_received': network.bytes_recv
                    },
                    'timestamp': datetime.now().isoformat()
                }
                
                # Store in Redis if available
                if self.redis:
                    await self.redis.setex(
                        'system_metrics', 
                        300,  # 5 minutes TTL
                        json.dumps(metrics)
                    )
                
                # Check for alerts
                await self.check_system_alerts(metrics)
                
                # Broadcast to WebSocket clients
                await self.broadcast_metrics(metrics)
                
            except Exception as e:
                print(f"Error collecting system metrics: {e}")
                
            await asyncio.sleep(60)  # Collect every minute

    async def collect_application_metrics(self):
        """Collect application-specific metrics"""
        while self.running:
            try:
                # Calculate throughput from recent requests
                current_time = datetime.now()
                minute_ago = current_time - timedelta(minutes=1)
                
                # This would typically query your application's request logs
                # For now, we'll simulate with stored data
                throughput = await self.calculate_throughput(minute_ago, current_time)
                self.metrics_history['throughput'].append(throughput)
                
                # Calculate error rates for different time periods
                error_rates = await self.calculate_error_rates()
                self.metrics_history['error_rates'] = deque(error_rates, maxlen=24)
                
            except Exception as e:
                print(f"Error collecting application metrics: {e}")
                
            await asyncio.sleep(60)  # Collect every minute

    async def calculate_throughput(self, start_time: datetime, end_time: datetime) -> int:
        """Calculate requests per minute"""
        # This would typically query your request logs
        # For demo purposes, return a simulated value
        import random
        return random.randint(50, 200)

    async def calculate_error_rates(self) -> List[float]:
        """Calculate error rates for different time periods"""
        # This would typically query your error logs
        # For demo purposes, return simulated values
        import random
        return [random.uniform(0, 5) for _ in range(4)]  # Last hour, 6h, 24h, week

    async def record_response_time(self, response_time: float):
        """Record a response time measurement"""
        self.metrics_history['response_times'].append(response_time)
        
        # Check for response time alerts
        if response_time > self.alert_thresholds['response_time']:
            await self.send_alert(
                'critical',
                'High Response Time',
                f'Response time of {response_time}ms exceeds threshold of {self.alert_thresholds["response_time"]}ms'
            )

    async def check_system_alerts(self, metrics: Dict[str, Any]):
        """Check system metrics against alert thresholds"""
        alerts = []
        
        if metrics['cpu_usage'] > self.alert_thresholds['cpu_usage']:
            alerts.append({
                'severity': 'warning' if metrics['cpu_usage'] < 90 else 'critical',
                'title': 'High CPU Usage',
                'description': f'CPU usage at {metrics["cpu_usage"]}%'
            })
            
        if metrics['memory_usage'] > self.alert_thresholds['memory_usage']:
            alerts.append({
                'severity': 'warning' if metrics['memory_usage'] < 95 else 'critical',
                'title': 'High Memory Usage',
                'description': f'Memory usage at {metrics["memory_usage"]}%'
            })
            
        if metrics['disk_usage'] > self.alert_thresholds['disk_usage']:
            alerts.append({
                'severity': 'critical',
                'title': 'High Disk Usage',
                'description': f'Disk usage at {metrics["disk_usage"]}%'
            })
            
        for alert in alerts:
            await self.send_alert(alert['severity'], alert['title'], alert['description'])

    async def send_alert(self, severity: str, title: str, description: str):
        """Send alert to monitoring systems and WebSocket clients"""
        alert = {
            'severity': severity,
            'title': title,
            'description': description,
            'timestamp': datetime.now().isoformat()
        }
        
        # Store alert in Redis
        if self.redis:
            await self.redis.lpush('alerts', json.dumps(alert))
            await self.redis.ltrim('alerts', 0, 99)  # Keep last 100 alerts
            
        # Broadcast to WebSocket clients
        await self.websocket_manager.broadcast_to_channel(
            'system_alerts',
            json.dumps({
                'channel': 'system_alerts',
                'payload': alert
            })
        )

    async def broadcast_metrics(self, metrics: Dict[str, Any]):
        """Broadcast current metrics to WebSocket clients"""
        # Add historical data
        metrics.update({
            'response_times': list(self.metrics_history['response_times']),
            'error_rates': list(self.metrics_history['error_rates']),
            'throughput': list(self.metrics_history['throughput'])[-1] if self.metrics_history['throughput'] else 0
        })
        
        await self.websocket_manager.broadcast_to_channel(
            'system_metrics',
            json.dumps({
                'channel': 'system_metrics',
                'payload': metrics
            })
        )

    async def get_current_metrics(self) -> Dict[str, Any]:
        """Get current system metrics"""
        if self.redis:
            cached_metrics = await self.redis.get('system_metrics')
            if cached_metrics:
                return json.loads(cached_metrics)
                
        # Fallback to real-time collection
        cpu_percent = psutil.cpu_percent()
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        network = psutil.net_io_counters()
        
        return {
            'cpu_usage': cpu_percent,
            'memory_usage': memory.percent,
            'disk_usage': (disk.used / disk.total) * 100,
            'network_io': {
                'bytes_sent': network.bytes_sent,
                'bytes_received': network.bytes_recv
            },
            'response_times': list(self.metrics_history['response_times']),
            'error_rates': list(self.metrics_history['error_rates']),
            'throughput': list(self.metrics_history['throughput'])[-1] if self.metrics_history['throughput'] else 0,
            'timestamp': datetime.now().isoformat()
        }

    async def check_alerts(self):
        """Periodic alert checking"""
        while self.running:
            try:
                # Check for any system-wide issues
                current_metrics = await self.get_current_metrics()
                await self.check_system_alerts(current_metrics)
                
            except Exception as e:
                print(f"Error in alert checking: {e}")
                
            await asyncio.sleep(300)  # Check every 5 minutes
```

---

## üéØ **Priority 4: Three-Engine Coordination Enhancement**

### **Implementation Plan**

#### **4.1 Enhanced Engine Coordinator**
```python
# Enhanced three-engine coordination system
from typing import Dict, List, Any, Optional
import asyncio
import json
from datetime import datetime
from enum import Enum
import uuid

class EngineType(Enum):
    PERFECT_RECALL = "perfect_recall"
    PARALLEL_MIND = "parallel_mind"
    CREATIVE = "creative"

class TaskPriority(Enum):
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class EngineTask:
    id: str
    engine_type: EngineType
    task_type: str
    payload: Dict[str, Any]
    priority: TaskPriority
    created_at: datetime
    dependencies: List[str] = None
    timeout: Optional[int] = None

@dataclass
class EngineStatus:
    engine_type: EngineType
    status: str  # 'idle', 'processing', 'overloaded', 'error'
    current_tasks: List[str]
    queue_size: int
    performance_metrics: Dict[str, float]
    last_update: datetime

class EnhancedEngineCoordinator:
    def __init__(self, websocket_manager):
        self.websocket_manager = websocket_manager
        self.engines: Dict[EngineType, Any] = {}
        self.engine_status: Dict[EngineType, EngineStatus] = {}
        self.task_queue: asyncio.PriorityQueue = asyncio.PriorityQueue()
        self.active_tasks: Dict[str, EngineTask] = {}
        self.task_results: Dict[str, Any] = {}
        self.coordination_rules = self._initialize_coordination_rules()
        
    def _initialize_coordination_rules(self) -> Dict[str, Any]:
        """Initialize coordination rules between engines"""
        return {
            'memory_tasks': {
                'primary_engine': EngineType.PERFECT_RECALL,
                'fallback_engines': [EngineType.PARALLEL_MIND],
                'max_concurrent': 10
            },
            'parallel_tasks': {
                'primary_engine': EngineType.PARALLEL_MIND,
                'fallback_engines': [EngineType.PERFECT_RECALL],
                'max_concurrent': 20
            },
            'creative_tasks': {
                'primary_engine': EngineType.CREATIVE,
                'fallback_engines': [EngineType.PARALLEL_MIND],
                'max_concurrent': 5
            },
            'hybrid_tasks': {
                'engines': [EngineType.PERFECT_RECALL, EngineType.PARALLEL_MIND, EngineType.CREATIVE],
                'coordination_strategy': 'pipeline'
            }
        }

    async def register_engine(self, engine_type: EngineType, engine_instance: Any):
        """Register an engine with the coordinator"""
        self.engines[engine_type] = engine_instance
        self.engine_status[engine_type] = EngineStatus(
            engine_type=engine_type,
            status='idle',
            current_tasks=[],
            queue_size=0,
            performance_metrics={
                'avg_response_time': 0.0,
                'success_rate': 100.0,
                'throughput': 0.0
            },
            last_update=datetime.now()
        )
        
        await self.broadcast_engine_status(engine_type)

    async def submit_task(self, task_type: str, payload: Dict[str, Any], 
                         priority: TaskPriority = TaskPriority.MEDIUM,
                         engine_preference: Optional[EngineType] = None) -> str:
        """Submit a task to the engine coordination system"""
        
        task_id = str(uuid.uuid4())
        
        # Determine optimal engine based on task type and current load
        target_engine = await self._determine_optimal_engine(
            task_type, engine_preference
        )
        
        task = EngineTask(
            id=task_id,
            engine_type=target_engine,
            task_type=task_type,
            payload=payload,
            priority=priority,
            created_at=datetime.now()
        )
        
        # Add to queue with priority
        await self.task_queue.put((priority.value, task))
        self.active_tasks[task_id] = task
        
        # Update engine status
        await self._update_engine_queue_size(target_engine)
        
        return task_id

    async def _determine_optimal_engine(self, task_type: str, 
                                      preference: Optional[EngineType] = None) -> EngineType:
        """Determine the optimal engine for a task"""
        
        # Check if user has a preference and engine is available
        if preference and self._is_engine_available(preference):
            return preference
            
        # Apply coordination rules
        if task_type in ['memory_query', 'knowledge_retrieval', 'context_search']:
            rule = self.coordination_rules['memory_tasks']
            if self._is_engine_available(rule['primary_engine']):
                return rule['primary_engine']
            else:
                for fallback in rule['fallback_engines']:
                    if self._is_engine_available(fallback):
                        return fallback
                        
        elif task_type in ['parallel_processing', 'batch_operation', 'concurrent_analysis']:
            rule = self.coordination_rules['parallel_tasks']
            if self._is_engine_available(rule['primary_engine']):
                return rule['primary_engine']
            else:
                for fallback in rule['fallback_engines']:
                    if self._is_engine_available(fallback):
                        return fallback
                        
        elif task_type in ['creative_generation', 'innovation', 'brainstorming']:
            rule = self.coordination_rules['creative_tasks']
            if self._is_engine_available(rule['primary_engine']):
                return rule['primary_engine']
            else:
                for fallback in rule['fallback_engines']:
                    if self._is_engine_available(fallback):
                        return fallback
        
        # Default to least loaded engine
        return self._get_least_loaded_engine()

    def _is_engine_available(self, engine_type: EngineType) -> bool:
        """Check if an engine is available for new tasks"""
        if engine_type not in self.engine_status:
            return False
            
        status = self.engine_status[engine_type]
        return (status.status in ['idle', 'processing'] and 
                status.queue_size < 50)  # Max queue size

    def _get_least_loaded_engine(self) -> EngineType:
        """Get the engine with the lowest current load"""
        min_load = float('inf')
        best_engine = EngineType.PARALLEL_MIND  # Default
        
        for engine_type, status in self.engine_status.items():
            if status.status != 'error':
                load = status.queue_size + len(status.current_tasks)
                if load < min_load:
                    min_load = load
                    best_engine = engine_type
                    
        return best_engine

    async def process_task_queue(self):
        """Process tasks from the queue"""
        while True:
            try:
                # Get next task from priority queue
                priority, task = await self.task_queue.get()
                
                # Execute task on assigned engine
                result = await self._execute_task(task)
                
                # Store result
                self.task_results[task.id] = result
                
                # Update engine status
                await self._update_engine_status_after_task(task.engine_type, task.id, True)
                
                # Broadcast task completion
                await self.broadcast_task_completion(task.id, result)
                
            except Exception as e:
                print(f"Error processing task: {e}")
                if 'task' in locals():
                    await self._update_engine_status_after_task(task.engine_type, task.id, False)

    async def _execute_task(self, task: EngineTask) -> Any:
        """Execute a task on the specified engine"""
        engine = self.engines[task.engine_type]
        
        # Update engine status to show task is being processed
        status = self.engine_status[task.engine_type]
        status.current_tasks.append(task.id)
        status.last_update = datetime.now()
        
        try:
            # Execute based on task type
            if task.task_type == 'memory_query':
                result = await engine.query_memory(task.payload)
            elif task.task_type == 'parallel_processing':
                result = await engine.process_parallel(task.payload)
            elif task.task_type == 'creative_generation':
                result = await engine.generate_creative(task.payload)
            else:
                # Generic execution
                result = await engine.execute(task.task_type, task.payload)
                
            return {
                'task_id': task.id,
                'status': 'completed',
                'result': result,
                'engine': task.engine_type.value,
                'execution_time': (datetime.now() - task.created_at).total_seconds()
            }
            
        except Exception as e:
            return {
                'task_id': task.id,
                'status': 'failed',
                'error': str(e),
                'engine': task.engine_type.value,
                'execution_time': (datetime.now() - task.created_at).total_seconds()
            }

    async def _update_engine_status_after_task(self, engine_type: EngineType, 
                                             task_id: str, success: bool):
        """Update engine status after task completion"""
        status = self.engine_status[engine_type]
        
        # Remove task from current tasks
        if task_id in status.current_tasks:
            status.current_tasks.remove(task_id)
            
        # Update performance metrics
        if success:
            # Update success rate and other metrics
            pass
        else:
            # Handle failure metrics
            pass
            
        status.last_update = datetime.now()
        
        # Determine new status
        if len(status.current_tasks) == 0 and status.queue_size == 0:
            status.status = 'idle'
        elif len(status.current_tasks) > 10:
            status.status = 'overloaded'
        else:
            status.status = 'processing'
            
        await self.broadcast_engine_status(engine_type)

    async def _update_engine_queue_size(self, engine_type: EngineType):
        """Update engine queue size"""
        # Count tasks in queue for this engine
        queue_size = sum(1 for _, task in list(self.task_queue._queue) 
                        if task.engine_type == engine_type)
        
        self.engine_status[engine_type].queue_size = queue_size
        await self.broadcast_engine_status(engine_type)

    async def broadcast_engine_status(self, engine_type: EngineType):
        """Broadcast engine status to WebSocket clients"""
        status = self.engine_status[engine_type]
        
        status_data = {
            'engine_type': engine_type.value,
            'status': status.status,
            'current_tasks': len(status.current_tasks),
            'queue_size': status.queue_size,
            'performance_metrics': status.performance_metrics,
            'last_update': status.last_update.isoformat()
        }
        
        await self.websocket_manager.broadcast_to_channel(
            'engine_status',
            json.dumps({
                'channel': 'engine_status',
                'payload': status_data
            })
        )

    async def broadcast_task_completion(self, task_id: str, result: Any):
        """Broadcast task completion to WebSocket clients"""
        await self.websocket_manager.broadcast_to_channel(
            'task_completion',
            json.dumps({
                'channel': 'task_completion',
                'payload': {
                    'task_id': task_id,
                    'result': result,
                    'timestamp': datetime.now().isoformat()
                }
            })
        )

    async def get_system_overview(self) -> Dict[str, Any]:
        """Get overview of all engines and their status"""
        return {
            'engines': {
                engine_type.value: {
                    'status': status.status,
                    'current_tasks': len(status.current_tasks),
                    'queue_size': status.queue_size,
                    'performance_metrics': status.performance_metrics
                }
                for engine_type, status in self.engine_status.items()
            },
            'total_active_tasks': len(self.active_tasks),
            'total_completed_tasks': len(self.task_results),
            'system_health': self._calculate_system_health()
        }

    def _calculate_system_health(self) -> str:
        """Calculate overall system health"""
        if not self.engine_status:
            return 'unknown'
            
        error_engines = sum(1 for status in self.engine_status.values() 
                           if status.status == 'error')
        
        if error_engines > 0:
            return 'degraded'
        
        overloaded_engines = sum(1 for status in self.engine_status.values() 
                               if status.status == 'overloaded')
        
        if overloaded_engines > len(self.engine_status) / 2:
            return 'stressed'
            
        return 'healthy'
```

---

## üöÄ **Implementation Timeline**

### **Week 1: Real-time Communication Enhancement**
- Day 1-2: Implement enhanced WebSocket service
- Day 3-4: Create real-time agent monitoring components
- Day 5-7: Integration testing and optimization

### **Week 2: Agent Coordination System**
- Day 1-3: Implement enhanced agent coordinator
- Day 4-5: Create agent status monitoring dashboard
- Day 6-7: Performance testing and tuning

### **Week 3: Production Monitoring**
- Day 1-3: Implement enhanced monitoring service
- Day 4-5: Create production monitoring dashboard
- Day 6-7: Alert system integration and testing

### **Week 4: Three-Engine Coordination**
- Day 1-3: Implement enhanced engine coordinator
- Day 4-5: Create engine coordination dashboard
- Day 6-7: End-to-end testing and optimization

---

## üìà **Expected Outcomes**

### **Performance Improvements**
- **Real-time Updates**: < 100ms latency for status updates
- **Agent Coordination**: 99.9% uptime with intelligent load balancing
- **Monitoring**: Comprehensive observability with proactive alerting
- **Engine Coordination**: Optimal task distribution and resource utilization

### **User Experience Enhancements**
- **Live Dashboard**: Real-time visibility into system status
- **Proactive Alerts**: Early warning system for issues
- **Performance Insights**: Detailed metrics and analytics
- **Seamless Integration**: Smooth frontend-backend communication

### **Production Readiness**
- **Scalability**: Handle 1000+ concurrent users
- **Reliability**: 99.9% uptime with automatic failover
- **Observability**: Complete monitoring and logging
- **Maintainability**: Clean, modular, and well-documented code

---

This implementation plan addresses the critical integration gaps while building upon your existing three-engine architecture foundation. The focus is on enhancing real-time communication, improving agent coordination, and optimizing production monitoring for enterprise-grade deployment.